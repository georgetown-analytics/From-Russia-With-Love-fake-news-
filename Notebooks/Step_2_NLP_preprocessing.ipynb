{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Capstone Project Data Wrangling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T22:39:23.151627Z",
     "start_time": "2021-01-09T22:39:17.731041Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-22316b6968e0>:10: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "/Users/ellemafa/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100000)\n",
    "pd.set_option('display.max_row', 1000000)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "import tldextract\n",
    "from tqdm.autonotebook import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\", leave=False)\n",
    "import string\n",
    "import spacy\n",
    "from spacy.lang import punctuation\n",
    "import unicodedata  # might need to pip install unicodedate2 on aws sagemaker\n",
    "import contractions\n",
    "from contractions import contractions_dict \n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import warnings\n",
    "from afinn import Afinn\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='darkgrid',palette='Dark2',rc={'figure.figsize':(9,6),'figure.dpi':90})\n",
    "\n",
    "punctuation = string.punctuation + '”' + '“' + '–' + '““' + \"’’\" + '”'\n",
    "stopword = stopwords.words('english')\n",
    "stopwords = set(STOPWORDS)\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T22:39:29.413468Z",
     "start_time": "2021-01-09T22:39:29.404470Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T22:45:25.608375Z",
     "start_time": "2021-01-09T22:39:33.354472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>real</td>\n",
       "      <td>The stunning announcement by Japanese and Amer...</td>\n",
       "      <td>Behind the Stem Cell Breakthrough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>real</td>\n",
       "      <td>We are halfway between the lunatic and the ter...</td>\n",
       "      <td>Quotation of the Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>real</td>\n",
       "      <td>There were Jews in Manhattan before there was ...</td>\n",
       "      <td>Celebrating Sounds Rooted In Gritty but Fertil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>real</td>\n",
       "      <td>To the Editor:\\n\\n“How Apple Sidesteps Billion...</td>\n",
       "      <td>What Apple Pays in Taxes, and Doesn't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>real</td>\n",
       "      <td>Katharine Winnifred Shergalis, a daughter of M...</td>\n",
       "      <td>Katharine Shergalis, Thomas Ewald</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        domain  type                                            content  \\\n",
       "0  nytimes.com  real  The stunning announcement by Japanese and Amer...   \n",
       "1  nytimes.com  real  We are halfway between the lunatic and the ter...   \n",
       "2  nytimes.com  real  There were Jews in Manhattan before there was ...   \n",
       "3  nytimes.com  real  To the Editor:\\n\\n“How Apple Sidesteps Billion...   \n",
       "4  nytimes.com  real  Katharine Winnifred Shergalis, a daughter of M...   \n",
       "\n",
       "                                               title  \n",
       "0                  Behind the Stem Cell Breakthrough  \n",
       "1                               Quotation of the Day  \n",
       "2  Celebrating Sounds Rooted In Gritty but Fertil...  \n",
       "3              What Apple Pays in Taxes, and Doesn't  \n",
       "4                  Katharine Shergalis, Thomas Ewald  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('FRL_Step_1_news_cleaned_2018_02_13.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T22:46:32.748138Z",
     "start_time": "2021-01-09T22:46:32.353160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1789474 entries, 0 to 1789473\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Dtype \n",
      "---  ------   ----- \n",
      " 0   domain   object\n",
      " 1   type     object\n",
      " 2   content  object\n",
      " 3   title    object\n",
      "dtypes: object(4)\n",
      "memory usage: 54.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the domain and check the unique domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T22:46:42.043606Z",
     "start_time": "2021-01-09T22:46:42.037606Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_domain(url):\n",
    "    \"\"\"\n",
    "    Extract domain name from fld url\n",
    "    \"\"\"\n",
    "    info = tldextract.extract(url)\n",
    "    return info.domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T22:47:12.624443Z",
     "start_time": "2021-01-09T22:47:01.185426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>real</td>\n",
       "      <td>The stunning announcement by Japanese and Amer...</td>\n",
       "      <td>Behind the Stem Cell Breakthrough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>real</td>\n",
       "      <td>We are halfway between the lunatic and the ter...</td>\n",
       "      <td>Quotation of the Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>real</td>\n",
       "      <td>There were Jews in Manhattan before there was ...</td>\n",
       "      <td>Celebrating Sounds Rooted In Gritty but Fertil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    domain  type                                            content  \\\n",
       "0  nytimes  real  The stunning announcement by Japanese and Amer...   \n",
       "1  nytimes  real  We are halfway between the lunatic and the ter...   \n",
       "2  nytimes  real  There were Jews in Manhattan before there was ...   \n",
       "\n",
       "                                               title  \n",
       "0                  Behind the Stem Cell Breakthrough  \n",
       "1                               Quotation of the Day  \n",
       "2  Celebrating Sounds Rooted In Gritty but Fertil...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['domain'] = df['domain'].astype(str).apply(extract_domain)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up the content column by removing all the noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-09T22:48:59.683561Z",
     "start_time": "2021-01-09T22:48:59.654565Z"
    }
   },
   "outputs": [],
   "source": [
    "# Portions of this are excerpts from Stack Overflow responses\n",
    "def remove_special_characters(text): \n",
    "    \"\"\"\n",
    "    Removes special characters from the text document\n",
    "    \"\"\"\n",
    "    # define the pattern to keep. You can check the regex using this url https://regexr.com/\n",
    "    pat = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]'\n",
    "    return re.sub(pat, '', text)\n",
    "\n",
    "def remove_extra_whitespace_tabs(text): \n",
    "    \"\"\"\n",
    "    Removes extra whitespaces and remove_extra_whitespace_tabs\n",
    "    \"\"\"\n",
    "    #pattern = r'^\\s+$|\\s+$'\n",
    "    pattern = r'^\\s*|\\s\\s*'\n",
    "    return re.sub(pattern, ' ', text).strip()\n",
    "\n",
    "def remove_digits(text): \n",
    "    \"\"\"\n",
    "    Remove all digits from the text document\n",
    "     take string input and return a clean text without numbers.\n",
    "        Use regex to discard the numbers.\n",
    "    \"\"\"\n",
    "    result = ''.join(i for i in text if not i.isdigit()).lower()\n",
    "    return ' '.join(result.split())\n",
    "\n",
    "def remove_newlines(text): \n",
    "    \"\"\"\n",
    "    Remove newline characters from the text document\n",
    "    \"\"\"\n",
    "    return text.replace('\\\\n', ' ').replace('\\\\r', ' ').replace('\\n', ' ').replace('\\r', ' ').replace('\\\\', ' ')\n",
    "\n",
    "#normalize to the NFKD (Normalization Form Compatibility Decomposition) form\n",
    "#that present in the Unicode standard to remain compatible with other encodings\n",
    "def remove_accented_chars(text): \n",
    "    \"\"\"\n",
    "    Removes accented characters from the test\n",
    "    \"\"\"\n",
    "    new_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return new_text\n",
    "\n",
    "\n",
    "import contractions\n",
    "contractions.fix(df['content'][10])\n",
    "\n",
    "\n",
    "\n",
    "#expands contractions found in the text\n",
    "def expand_contractions(text):\n",
    "\n",
    "\n",
    "    #contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), flags=re.IGNORECASE|re.DOTALL)\n",
    "    #def expand_match(contraction):\n",
    "    #    match = contraction.group(0)\n",
    "    #    first_char = match[0]\n",
    "    #    expanded_contraction = contraction_mapping.get(match)\\\n",
    "    #                            if contraction_mapping.get(match)\\\n",
    "    #                            else contraction_mapping.get(match.lower())\n",
    "    #    expanded_contraction = first_char+expanded_contraction[1:]\n",
    "    #    return expanded_contraction\n",
    "\n",
    "    expanded_text = contractions.fix(text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "# replace punctuation characters with spaces\n",
    "def replace_punctuation(text):\n",
    "    filters = string.punctuation + '”' + '“' + '–' \n",
    "    translate_dict = dict((c, \" \") for c in filters)   \n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "    return text\n",
    "\n",
    "# Remove stopwords and remove words with 2 or less characters\n",
    "def stops_letters(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2 and token not in stopword:\n",
    "            result.append(token)\n",
    "            \n",
    "    return \" \".join(result)\n",
    "\n",
    "#Removes any word that starts with either http or https\n",
    "def remove_urls(vTEXT):\n",
    "    #vTEXT = re.sub('http://\\S+|https://\\S+', '', vTEXT,flags=re.MULTILINE)\n",
    "    vTEXT = re.sub('http[s]?://\\S+', '', vTEXT,flags=re.MULTILINE)\n",
    "    return(vTEXT)\n",
    "\n",
    "#Remove words that starts with www\n",
    "def remove_www(vTEXT):\n",
    "    vTEXT = re.sub('www\\S+', '', vTEXT,flags=re.MULTILINE)\n",
    "    return(vTEXT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covert Content and Title Fields to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T01:57:18.689020Z",
     "start_time": "2021-01-09T22:50:20.310567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.42 s, sys: 52.3 ms, total: 3.47 s\n",
      "Wall time: 3.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Apply the functions to the dataframe\n",
    "\n",
    "# Step 1 - convert the text to lower case\n",
    "df['content']=df['content'].apply(lambda x: x.lower())\n",
    "df['title']=df['title'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove URLS from Content and Title Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T01:57:18.689020Z",
     "start_time": "2021-01-09T22:50:20.310567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.18 s, sys: 16.7 ms, total: 8.2 s\n",
      "Wall time: 8.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#step 2 - Remove URLS\n",
    "df['content']=df['content'].apply(remove_urls)\n",
    "df['title'] = df['title'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove website www from Content and Title Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T01:57:18.689020Z",
     "start_time": "2021-01-09T22:50:20.310567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.23 s, sys: 14.6 ms, total: 7.25 s\n",
      "Wall time: 7.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#step 3 - Remove www\n",
    "df['content']=df['content'].apply(remove_www)\n",
    "df['title'] = df['title'].apply(remove_www)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove special characters from Content and Title Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T01:57:18.689020Z",
     "start_time": "2021-01-09T22:50:20.310567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.6 s, sys: 31.6 ms, total: 38.6 s\n",
      "Wall time: 38.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Step 4 - remove special charcaters\n",
    "df['content']=df['content'].apply(remove_special_characters)\n",
    "df['title'] = df['title'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove whitespace from Content and Title Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T01:57:18.689020Z",
     "start_time": "2021-01-09T22:50:20.310567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 42s, sys: 1.33 s, total: 4min 44s\n",
      "Wall time: 4min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#step 5 - Remove whitespaces and tabs\n",
    "df['content']=df['content'].apply(remove_extra_whitespace_tabs)\n",
    "df['title'] = df['title'].apply(remove_extra_whitespace_tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove website www from Content and Title Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T01:57:18.689020Z",
     "start_time": "2021-01-09T22:50:20.310567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 12.8 ms, total: 10.3 s\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#step 6 - remove newlines and tabs\n",
    "df['content'] = df['content'].apply(remove_newlines)\n",
    "df['title'] = df['title'].apply(remove_newlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove digits from Content and Title Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T01:57:18.689020Z",
     "start_time": "2021-01-09T22:50:20.310567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 17s, sys: 389 ms, total: 6min 17s\n",
      "Wall time: 6min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# step 7 - Remove digits\n",
    "df['content']=df['content'].apply(remove_digits)\n",
    "df['title'] = df['title'].apply(remove_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove accented characters from Content and Title Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T01:57:18.689020Z",
     "start_time": "2021-01-09T22:50:20.310567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.2 s, sys: 536 ms, total: 10.7 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#step 8 - remove accented characters\n",
    "df['content']=df['content'].apply(remove_accented_chars)\n",
    "df['title'] = df['title'].apply(remove_accented_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand Contractions within Content and Title Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T01:57:18.689020Z",
     "start_time": "2021-01-09T22:50:20.310567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 51s, sys: 1.74 s, total: 4min 53s\n",
      "Wall time: 4min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#step 9 - Expand contractions\n",
    "df['content']=df['content'].apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctions from Content and Title Fields, replace with single space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T01:57:18.689020Z",
     "start_time": "2021-01-09T22:50:20.310567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.9 s, sys: 6.06 s, total: 38 s\n",
      "Wall time: 43.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#step 10 - Replace punctuations with spaces \n",
    "df['content']= df['content'].apply(replace_punctuation)\n",
    "df['title'] = df['title'].apply(replace_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop letters from Content and Title Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T01:57:18.689020Z",
     "start_time": "2021-01-09T22:50:20.310567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27min 58s, sys: 2.68 s, total: 28min 1s\n",
      "Wall time: 1h 11min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#step 11 - Remove stopwords, tokenize and remove words with 2 or less characters\n",
    "df['content']= df['content'].apply(stops_letters)\n",
    "df['title'] = df['title'].apply(stops_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affinity Score - Sentiment Analyis - Content Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the affinity score of a list of tweets\n",
    "afinn = Afinn()\n",
    "\n",
    "def get_affinity_scores(tweets):\n",
    "    scores = []\n",
    "    count = 0\n",
    "    for t in tweets:\n",
    "        if len(t) > 0:\n",
    "            scores.append(afinn.score(t) / len(t))\n",
    "        else:\n",
    "            count += 1\n",
    "            scores.append(0)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_affin = get_affinity_scores(df['content'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content_affin'] = new_affin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./FRL_Step_2_news_cleaned_2018_02_13.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>content_affin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>real</td>\n",
       "      <td>stunning announcement japanese american resear...</td>\n",
       "      <td>stem cell breakthrough</td>\n",
       "      <td>-0.001577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>real</td>\n",
       "      <td>halfway lunatic terrorist line petty crime qae...</td>\n",
       "      <td>quotation day</td>\n",
       "      <td>-0.091603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>real</td>\n",
       "      <td>jews manhattan new york city boat jews arrived...</td>\n",
       "      <td>celebrating sounds rooted gritty fertile new turf</td>\n",
       "      <td>0.009639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>real</td>\n",
       "      <td>editor apple sidesteps billions taxes ieconomy...</td>\n",
       "      <td>apple pays taxes</td>\n",
       "      <td>0.022202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>real</td>\n",
       "      <td>katharine winnifred shergalis daughter mrs edw...</td>\n",
       "      <td>katharine shergalis thomas ewald</td>\n",
       "      <td>-0.001033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    domain  type                                            content  \\\n",
       "0  nytimes  real  stunning announcement japanese american resear...   \n",
       "1  nytimes  real  halfway lunatic terrorist line petty crime qae...   \n",
       "2  nytimes  real  jews manhattan new york city boat jews arrived...   \n",
       "3  nytimes  real  editor apple sidesteps billions taxes ieconomy...   \n",
       "4  nytimes  real  katharine winnifred shergalis daughter mrs edw...   \n",
       "\n",
       "                                               title  content_affin  \n",
       "0                             stem cell breakthrough      -0.001577  \n",
       "1                                      quotation day      -0.091603  \n",
       "2  celebrating sounds rooted gritty fertile new turf       0.009639  \n",
       "3                                   apple pays taxes       0.022202  \n",
       "4                   katharine shergalis thomas ewald      -0.001033  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization - Lemmatize the title and content columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T01:58:07.650308Z",
     "start_time": "2021-01-10T01:58:07.572329Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ellemafa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ellemafa/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "  \n",
    "\n",
    "def lemmatized_word(text):\n",
    "    \"\"\"\n",
    "    lemmatize the text so as to get its root form \n",
    "    \"\"\"\n",
    "    word_tokens = nltk.word_tokenize(text)\n",
    "    lemmatized_word = [wordnet_lemmatizer.lemmatize(word) for word in word_tokens]\n",
    "    return  \" \".join(lemmatized_word) #combine the words into a giant string that vectorizer can accept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T03:09:23.442224Z",
     "start_time": "2021-01-10T01:58:13.909439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='progress-bar', max=1789474.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='progress-bar', max=1789474.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['content'] = df['content'].progress_apply(lemmatized_word)\n",
    "df['title'] = df['title'].progress_apply(lemmatized_word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T03:13:20.318055Z",
     "start_time": "2021-01-10T03:12:00.090022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 1.14 s, total: 1min 7s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# word counts\n",
    "df['c_word_count'] = df[\"content\"].apply(lambda x: len(str(x).split(\" \")))\n",
    "df['t_word_count'] = df[\"title\"].apply(lambda x: len(str(x).split(\" \")))\n",
    "\n",
    "# Character counts\n",
    "df['c_character_count'] = df[\"content\"].apply(lambda x: sum(len(word) for word in str(x).split(\" \")))\n",
    "df['t_character_count'] = df[\"title\"].apply(lambda x: sum(len(word) for word in str(x).split(\" \")))\n",
    "\n",
    "#average word length\n",
    "df['c_avg_word_length'] = df['c_character_count'] / df['c_word_count']\n",
    "df['t_avg_word_length'] = df['t_character_count'] / df['t_word_count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./FRL_Step_2_1_news_cleaned_2018_02_13.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify sentiment in the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T03:13:30.705903Z",
     "start_time": "2021-01-10T03:13:30.678900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add a new plot that shows the distribution of scores \n",
    "\n",
    "def sentiment_check (text):\n",
    "    polarity_score = TextBlob(text).sentiment.polarity\n",
    "    df['title_sentiment_score'] = polarity_score\n",
    "    if polarity_score < 0:\n",
    "        return 'negative'\n",
    "    elif polarity_score == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T03:19:07.082842Z",
     "start_time": "2021-01-10T03:13:37.592627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 35min 23s, sys: 15min 40s, total: 1h 51min 4s\n",
      "Wall time: 2h 59min 43s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>type</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>content_affin</th>\n",
       "      <th>c_word_count</th>\n",
       "      <th>t_word_count</th>\n",
       "      <th>c_character_count</th>\n",
       "      <th>t_character_count</th>\n",
       "      <th>c_avg_word_length</th>\n",
       "      <th>t_avg_word_length</th>\n",
       "      <th>title_sentiment_label</th>\n",
       "      <th>title_sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>real</td>\n",
       "      <td>stunning announcement japanese american resear...</td>\n",
       "      <td>stem cell breakthrough</td>\n",
       "      <td>-0.001577</td>\n",
       "      <td>154</td>\n",
       "      <td>3</td>\n",
       "      <td>1084</td>\n",
       "      <td>20</td>\n",
       "      <td>7.038961</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>real</td>\n",
       "      <td>halfway lunatic terrorist line petty crime qae...</td>\n",
       "      <td>quotation day</td>\n",
       "      <td>-0.091603</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>114</td>\n",
       "      <td>12</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>real</td>\n",
       "      <td>jew manhattan new york city boat jew arrived n...</td>\n",
       "      <td>celebrating sound rooted gritty fertile new turf</td>\n",
       "      <td>0.009639</td>\n",
       "      <td>214</td>\n",
       "      <td>7</td>\n",
       "      <td>1416</td>\n",
       "      <td>42</td>\n",
       "      <td>6.616822</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    domain  type                                            content  \\\n",
       "0  nytimes  real  stunning announcement japanese american resear...   \n",
       "1  nytimes  real  halfway lunatic terrorist line petty crime qae...   \n",
       "2  nytimes  real  jew manhattan new york city boat jew arrived n...   \n",
       "\n",
       "                                              title  content_affin  \\\n",
       "0                            stem cell breakthrough      -0.001577   \n",
       "1                                     quotation day      -0.091603   \n",
       "2  celebrating sound rooted gritty fertile new turf       0.009639   \n",
       "\n",
       "   c_word_count  t_word_count  c_character_count  t_character_count  \\\n",
       "0           154             3               1084                 20   \n",
       "1            18             2                114                 12   \n",
       "2           214             7               1416                 42   \n",
       "\n",
       "   c_avg_word_length  t_avg_word_length title_sentiment_label  \\\n",
       "0           7.038961           6.666667               neutral   \n",
       "1           6.333333           6.000000               neutral   \n",
       "2           6.616822           6.000000              positive   \n",
       "\n",
       "   title_sentiment_score  \n",
       "0                    0.0  \n",
       "1                    0.0  \n",
       "2                    0.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df['title_sentiment_label'] = df['title'].apply(sentiment_check)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./FRL_Step_2_full_features_news_cleaned_2018_02_13.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T03:24:03.966344Z",
     "start_time": "2021-01-10T03:24:03.517700Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.rename({'type': 'label'}, axis=1)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rearranged the order of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T03:24:08.971452Z",
     "start_time": "2021-01-10T03:24:08.360452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>content_affin</th>\n",
       "      <th>c_word_count</th>\n",
       "      <th>t_word_count</th>\n",
       "      <th>c_character_count</th>\n",
       "      <th>t_character_count</th>\n",
       "      <th>c_avg_word_length</th>\n",
       "      <th>t_avg_word_length</th>\n",
       "      <th>title_sentiment_label</th>\n",
       "      <th>title_sentiment_score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>stem cell breakthrough</td>\n",
       "      <td>stunning announcement japanese american resear...</td>\n",
       "      <td>-0.001577</td>\n",
       "      <td>154</td>\n",
       "      <td>3</td>\n",
       "      <td>1084</td>\n",
       "      <td>20</td>\n",
       "      <td>7.038961</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>quotation day</td>\n",
       "      <td>halfway lunatic terrorist line petty crime qae...</td>\n",
       "      <td>-0.091603</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>114</td>\n",
       "      <td>12</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>celebrating sound rooted gritty fertile new turf</td>\n",
       "      <td>jew manhattan new york city boat jew arrived n...</td>\n",
       "      <td>0.009639</td>\n",
       "      <td>214</td>\n",
       "      <td>7</td>\n",
       "      <td>1416</td>\n",
       "      <td>42</td>\n",
       "      <td>6.616822</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    domain                                             title  \\\n",
       "0  nytimes                            stem cell breakthrough   \n",
       "1  nytimes                                     quotation day   \n",
       "2  nytimes  celebrating sound rooted gritty fertile new turf   \n",
       "\n",
       "                                             content  content_affin  \\\n",
       "0  stunning announcement japanese american resear...      -0.001577   \n",
       "1  halfway lunatic terrorist line petty crime qae...      -0.091603   \n",
       "2  jew manhattan new york city boat jew arrived n...       0.009639   \n",
       "\n",
       "   c_word_count  t_word_count  c_character_count  t_character_count  \\\n",
       "0           154             3               1084                 20   \n",
       "1            18             2                114                 12   \n",
       "2           214             7               1416                 42   \n",
       "\n",
       "   c_avg_word_length  t_avg_word_length title_sentiment_label  \\\n",
       "0           7.038961           6.666667               neutral   \n",
       "1           6.333333           6.000000               neutral   \n",
       "2           6.616822           6.000000              positive   \n",
       "\n",
       "   title_sentiment_score label  \n",
       "0                    0.0  real  \n",
       "1                    0.0  real  \n",
       "2                    0.0  real  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['domain','title','content', 'content_affin','c_word_count','t_word_count','c_character_count','t_character_count','c_avg_word_length','t_avg_word_length','title_sentiment_label', 'title_sentiment_score','label']]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T03:24:15.527174Z",
     "start_time": "2021-01-10T03:24:15.017176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1789474 entries, 0 to 1789473\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   domain                 object \n",
      " 1   title                  object \n",
      " 2   content                object \n",
      " 3   content_affin          float64\n",
      " 4   c_word_count           int64  \n",
      " 5   t_word_count           int64  \n",
      " 6   c_character_count      int64  \n",
      " 7   t_character_count      int64  \n",
      " 8   c_avg_word_length      float64\n",
      " 9   t_avg_word_length      float64\n",
      " 10  title_sentiment_label  object \n",
      " 11  title_sentiment_score  float64\n",
      " 12  label                  object \n",
      "dtypes: float64(4), int64(4), object(5)\n",
      "memory usage: 177.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T03:38:06.192463Z",
     "start_time": "2021-01-10T03:38:06.141472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>content_affin</th>\n",
       "      <th>c_word_count</th>\n",
       "      <th>t_word_count</th>\n",
       "      <th>c_character_count</th>\n",
       "      <th>t_character_count</th>\n",
       "      <th>c_avg_word_length</th>\n",
       "      <th>t_avg_word_length</th>\n",
       "      <th>title_sentiment_label</th>\n",
       "      <th>title_sentiment_score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>stem cell breakthrough</td>\n",
       "      <td>stunning announcement japanese american resear...</td>\n",
       "      <td>-0.001577</td>\n",
       "      <td>154</td>\n",
       "      <td>3</td>\n",
       "      <td>1084</td>\n",
       "      <td>20</td>\n",
       "      <td>7.038961</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>quotation day</td>\n",
       "      <td>halfway lunatic terrorist line petty crime qae...</td>\n",
       "      <td>-0.091603</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>114</td>\n",
       "      <td>12</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>celebrating sound rooted gritty fertile new turf</td>\n",
       "      <td>jew manhattan new york city boat jew arrived n...</td>\n",
       "      <td>0.009639</td>\n",
       "      <td>214</td>\n",
       "      <td>7</td>\n",
       "      <td>1416</td>\n",
       "      <td>42</td>\n",
       "      <td>6.616822</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.0</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>apple pay tax</td>\n",
       "      <td>editor apple sidestep billion tax ieconomy ser...</td>\n",
       "      <td>0.022202</td>\n",
       "      <td>142</td>\n",
       "      <td>3</td>\n",
       "      <td>907</td>\n",
       "      <td>11</td>\n",
       "      <td>6.387324</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    domain                                             title  \\\n",
       "0  nytimes                            stem cell breakthrough   \n",
       "1  nytimes                                     quotation day   \n",
       "2  nytimes  celebrating sound rooted gritty fertile new turf   \n",
       "3  nytimes                                     apple pay tax   \n",
       "\n",
       "                                             content  content_affin  \\\n",
       "0  stunning announcement japanese american resear...      -0.001577   \n",
       "1  halfway lunatic terrorist line petty crime qae...      -0.091603   \n",
       "2  jew manhattan new york city boat jew arrived n...       0.009639   \n",
       "3  editor apple sidestep billion tax ieconomy ser...       0.022202   \n",
       "\n",
       "   c_word_count  t_word_count  c_character_count  t_character_count  \\\n",
       "0           154             3               1084                 20   \n",
       "1            18             2                114                 12   \n",
       "2           214             7               1416                 42   \n",
       "3           142             3                907                 11   \n",
       "\n",
       "   c_avg_word_length  t_avg_word_length title_sentiment_label  \\\n",
       "0           7.038961           6.666667               neutral   \n",
       "1           6.333333           6.000000               neutral   \n",
       "2           6.616822           6.000000              positive   \n",
       "3           6.387324           3.666667               neutral   \n",
       "\n",
       "   title_sentiment_score label  \n",
       "0                    0.0  real  \n",
       "1                    0.0  real  \n",
       "2                    0.0  real  \n",
       "3                    0.0  real  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the preprocessed dataframe to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T03:38:52.968390Z",
     "start_time": "2021-01-10T03:38:52.956389Z"
    }
   },
   "outputs": [],
   "source": [
    "# path to save the preprocessed csv file\n",
    "df.to_csv(\"./FRL_Step_2_full_features_news_cleaned_2018_02_13.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
